# Story 3.3: Prospect Comparison Tool

## Status
Draft

## Story

**As a** dynasty fantasy player,
**I want** to compare multiple prospects side-by-side,
**so that** I can make informed decisions about trades and draft selections.

## Acceptance Criteria

1. Side-by-side comparison interface supporting 2-4 prospects simultaneously
2. Key metrics comparison with visual indicators for advantages/disadvantages
3. ML prediction and confidence level comparison with explanatory differences
4. Statistical trend comparison charts over time
5. Scouting grade radar charts for visual profile comparison
6. Historical analog comparison showing similar past prospects
7. Dynasty timeline comparison (ETA and development stage alignment)
8. Comparison export and sharing functionality

## Tasks / Subtasks

- [ ] Task 1: Backend API Enhancement for Comparison Data (AC: 1, 2, 3, 6)
  - [ ] Extend GET /api/prospects/compare endpoint for multi-prospect comparison
  - [ ] Add comparative ML prediction analysis with confidence differential scoring
  - [ ] Implement historical analog comparison service using feature similarity
  - [ ] Add statistical aggregation and comparative metrics calculation
  - [ ] Include comparative caching strategy (15-minute TTL for comparison data)

- [ ] Task 2: Comparison Interface Layout and Prospect Selection (AC: 1)
  - [ ] Create ProspectComparison component with drag-and-drop prospect selection
  - [ ] Implement 2-4 prospect slots with add/remove functionality
  - [ ] Build responsive side-by-side comparison table layout
  - [ ] Add prospect search and selection modal for easy prospect addition
  - [ ] Include comparison URL generation for bookmarkable comparisons

- [ ] Task 3: Metrics Comparison with Visual Indicators (AC: 2)
  - [ ] Create comparative metrics display with advantage/disadvantage highlighting
  - [ ] Implement visual indicators (✓, colors, percentage differences)
  - [ ] Add key metrics selection and customization functionality
  - [ ] Build expandable metric sections for detailed comparisons
  - [ ] Include metric explanation tooltips and context

- [ ] Task 4: ML Prediction Comparison Display (AC: 3)
  - [ ] Create comparative ML prediction visualization
  - [ ] Implement SHAP value difference analysis and display
  - [ ] Add confidence level comparison with explanatory narratives
  - [ ] Build prediction timeline comparison showing development probability
  - [ ] Include model explanation differential highlighting

- [ ] Task 5: Statistical Trend Comparison Charts (AC: 4)
  - [ ] Create multi-prospect performance trend chart component
  - [ ] Implement overlaid timeline charts for statistical progression
  - [ ] Add league-adjusted performance comparison metrics
  - [ ] Build interactive chart controls for time range and metric selection
  - [ ] Include trend direction indicators and performance trajectory analysis

- [ ] Task 6: Scouting Grade Radar Comparison (AC: 5)
  - [ ] Extend ScoutingRadar component for multi-prospect overlay
  - [ ] Implement radar chart comparison with multiple prospect profiles
  - [ ] Add grade progression timeline comparison for scouting development
  - [ ] Build source attribution comparison showing grade consistency
  - [ ] Include grade differential highlighting and analysis

- [ ] Task 7: Historical Analog Comparison System (AC: 6)
  - [ ] Create historical prospect analog comparison service
  - [ ] Implement ML-based similarity matching for past prospect outcomes
  - [ ] Build analog prospect display with MLB career outcomes
  - [ ] Add confidence scoring for historical similarity matching
  - [ ] Include analog narrative generation explaining similarity factors

- [ ] Task 8: Dynasty Timeline and ETA Comparison (AC: 7)
  - [ ] Create dynasty timeline comparison visualization
  - [ ] Implement ETA progression and development stage alignment
  - [ ] Add organizational depth chart context for timing comparison
  - [ ] Build dynasty value projection comparison with timeline context
  - [ ] Include trade window and opportunity analysis

- [ ] Task 9: Export and Sharing Functionality (AC: 8)
  - [ ] Implement comparison export to PDF and CSV formats
  - [ ] Create shareable comparison URLs with metadata
  - [ ] Add social sharing integration for comparison results
  - [ ] Build comparison summary generation for export
  - [ ] Include comparison history and saved comparison functionality

- [ ] Task 10: Testing Implementation
  - [ ] Write unit tests for comparison API endpoints using pytest
  - [ ] Create integration tests for multi-prospect comparison workflows
  - [ ] Build component tests for comparison interface using Jest/React Testing Library
  - [ ] Add end-to-end tests for complete comparison workflows
  - [ ] Implement performance testing for comparison data loading with complex analytics

## Dev Notes

### Previous Story Insights
From Stories 2.1-2.5: Complete ML prediction infrastructure with SHAP explanations established, Redis caching system (24-hour TTL for predictions), FastAPI application structure, comprehensive prospect data pipeline, and AI narrative generation. Database schema includes prospects, prospect_stats (TimescaleDB), ml_predictions, and scouting_grades tables. From Stories 3.1-3.2: Dynasty ranking system, fuzzy search service, ProspectCard component, ScoutingRadar component, PerformanceTrends component, and comprehensive prospect profile system with 1-hour profile caching established.

### Data Models
**Core Comparison Data Schema:**
[Source: technical-architecture/5-database-design.md#core-schema]
- **prospects table**: id, mlb_id, name, position, organization, level, age, eta_year with indexes on organization, position, eta_year
- **prospect_stats table**: TimescaleDB hypertable with batting/pitching statistics, performance metrics (woba, wrc_plus) partitioned by date_recorded for time-series analysis
- **ml_predictions table**: success_probability, confidence_level (High/Medium/Low), feature_importance (JSONB with SHAP values), narrative with composite index on (prospect_id, generated_at DESC)
- **scouting_grades table**: Multi-source scouting data (20-80 scale) with source attribution, overall_grade, hit_grade, power_grade, speed_grade, field_grade, arm_grade, and updated_at timestamps

**Comparison Data Aggregation:**
[Source: technical-architecture/3-ml-infrastructure.md#training-pipeline]
- **ML Features**: 50+ engineered features including age-adjusted performance metrics, level progression rates, scouting grades normalized to 20-80 scale for similarity calculations
- **Historical Comparisons**: Feature similarity matching using ML algorithms for analog prospect identification
- **Model Versioning**: MLflow experiment tracking for consistent comparison across model versions

### API Specifications
**Comparison Endpoints:**
[Source: technical-architecture/4-api-layer.md#prospect-data]
```python
@app.get("/api/prospects/compare")
@limiter.limit("50/minute")
async def compare_prospects(
    prospect_ids: str,  # Comma-separated IDs (2-4 prospects)
    include_stats: bool = True,
    include_predictions: bool = True,
    include_analogs: bool = True,
    user: User = Depends(get_current_user)
):
    # Return comprehensive comparison data for multiple prospects
    pass

@app.get("/api/prospects/compare/analogs")
async def get_comparison_analogs(
    prospect_ids: str,
    limit: int = 3,
    user: User = Depends(get_current_user)
):
    # Return historical analog prospects for comparison group
    pass

@app.post("/api/prospects/compare/export")
async def export_comparison(
    prospect_ids: str,
    format: str,  # 'pdf' or 'csv'
    user: User = Depends(get_current_user)
):
    # Generate and return comparison export
    pass
```

**Comparison Analytics:**
[Source: technical-architecture/3-ml-infrastructure.md#inference-service]
- **SHAP Differential Analysis**: Compare SHAP values between prospects to highlight prediction differences
- **Statistical Significance**: Determine meaningful differences in performance metrics
- **Confidence Scoring**: Comparative confidence levels with differential analysis

### Component Specifications
**Comparison Tool Layout:**
[Source: ux-architecture/3-wireframe-specifications.md#prospect-comparison-tool]
- **Desktop Layout**: Header with export/share options, prospect selector with drag-and-drop functionality, side-by-side comparison table, radar chart overlay section
- **Prospect Selector**: Add/remove prospects with search modal, support for 2-4 prospects simultaneously
- **Comparison Table**: Metric rows with visual advantage indicators (✓, colors, percentage differences), expandable sections for detailed metrics
- **Interactive Elements**: Metric highlighting, comparative analysis tooltips, exportable summary generation

**Chart Components:**
[Source: ux-architecture/3-wireframe-specifications.md#prospect-comparison-tool]
- **Radar Chart Overlay**: Multi-prospect scouting grade visualization with color-coded prospects
- **Performance Trend Overlay**: Timeline charts showing statistical progression for multiple prospects
- **AI Analysis Summary**: Generated narrative explaining key differences and recommendations

### File Locations
**Frontend Components:**
[Source: Project structure analysis and Stories 3.1-3.2 implementations]
- **Main Comparison Page**: `apps/web/src/app/compare/page.tsx` (new route)
- **Comparison Component**: `apps/web/src/components/prospects/ProspectComparison.tsx` (new component)
- **Comparison Table**: `apps/web/src/components/prospects/ComparisonTable.tsx` (new component)
- **Prospect Selector**: `apps/web/src/components/prospects/ProspectSelector.tsx` (new component)
- **Radar Overlay**: `apps/web/src/components/prospects/ScoutingRadar.tsx` (extend existing for multi-prospect)
- **Trend Overlay**: `apps/web/src/components/prospects/PerformanceTrends.tsx` (extend existing for multi-prospect)
- **Export Component**: `apps/web/src/components/ui/ComparisonExport.tsx` (new component)
- **Hooks**: `apps/web/src/hooks/useProspectComparison.ts` (new hook)

**Backend Implementation:**
[Source: Existing API structure from Stories 2.3-2.5 and 3.1-3.2]
- **Comparison API**: `apps/api/app/api/api_v1/endpoints/prospects.py` (extend existing with comparison endpoints)
- **Comparison Service**: `apps/api/app/services/prospect_comparison_service.py` (extend existing from Story 3.2)
- **Analytics Service**: `apps/api/app/services/comparison_analytics_service.py` (new service)
- **Export Service**: `apps/api/app/services/export_service.py` (new service)

**Testing Structure:**
- **Frontend Tests**: `apps/web/src/components/prospects/__tests__/ProspectComparison.test.tsx` (new test file)
- **Comparison API Tests**: `apps/api/tests/api/test_prospect_comparison.py` (new test file)
- **Integration Tests**: `apps/api/tests/integration/test_comparison_workflow.py` (new test file)

### Technical Constraints
**Performance Requirements:**
[Source: technical-architecture/technical-constraints-considerations.md#performance-requirements]
- **Comparison Load**: <2 seconds for 2-4 prospect comparison with full analytics
- **ML Comparison**: <1 second for SHAP differential analysis generation
- **Chart Rendering**: <500ms for radar and trend chart overlay rendering
- **Export Generation**: <5 seconds for PDF export with comprehensive data

**Caching Strategy:**
[Source: technical-architecture/4-api-layer.md#api-response-caching]
- **Comparison Data**: 15-minute TTL for prospect comparison datasets, invalidated on data changes
- **Analog Data**: 12-hour TTL for historical analog comparisons, updated with model retraining
- **Export Cache**: 5-minute TTL for generated export files to prevent duplicate processing
- **Chart Data**: 30-minute TTL for statistical trend and radar chart data

**Authentication & Rate Limiting:**
[Source: technical-architecture/1-system-overview.md#api-gateway-layer]
- **Rate Limiting**: 50/min for comparison endpoints, 200/min for premium users
- **JWT Authentication**: Required for all comparison endpoints
- **Export Limits**: Free users limited to 5 exports per day, premium unlimited

### Project Structure Notes
Comparison tool builds on existing ProspectComparison service from Story 3.2, ScoutingRadar and PerformanceTrends components. TimescaleDB hypertable structure supports efficient multi-prospect statistical queries. Existing SHAP explanation infrastructure enables comparative ML analysis. Redis caching infrastructure supports comparison data caching. Next.js routing supports dedicated comparison page. Export functionality leverages established PDF generation patterns.

### Testing

**Testing Standards:**
[Source: Existing testing patterns from Stories 2.3-2.5 and 3.1-3.2]
- **Frontend**: Jest + React Testing Library for component testing, including drag-and-drop interactions, comparison table behavior, and chart overlay functionality
- **Backend**: pytest framework for API endpoint testing with multi-prospect comparison scenarios
- **Integration**: End-to-end testing with real database interactions for complete comparison workflows
- **Performance**: Load testing for comparison page performance with complex multi-prospect analytics
- **Export Testing**: Validation of PDF and CSV export functionality with comprehensive data integrity checks

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|---------|
| 2025-09-26 | 1.0 | Initial story creation with comprehensive comparison tool context | Bob (Scrum Master) |